# -*- coding: utf-8 -*-
"""roynes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1akTlEVzftzDzX2xvz5m_k9YscvrI4PbI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv('data.csv')
print(data.head())

# Separate the features and target variable
X = features.values
y = df["y"].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Use Lasso Regression for feature selection
lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)

# Determine the number of features to select
num_features = 12

# Subset the training and testing data with the selected features based on their coefficients
selected_features = features.columns[lasso.coef_ != 0]
X_train_selected = X_train[:, lasso.coef_ != 0]
X_test_selected = X_test[:, lasso.coef_ != 0]

# Use Ridge Regression to model the dataset
ridge = Ridge(alpha=0.1)
ridge.fit(X_train_selected, y_train)
y_pred = ridge.predict(X_test_selected)

# Calculate RMSE and R2 Score
rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)
print("RMSE:", rmse)
print("R2 Score:", r2)

# Plot the line of best fit
plt.scatter(y_test, y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Line of Best Fit")
plt.show()
